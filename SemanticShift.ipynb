{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f56e713b-f837-420d-b424-d21d47477eae",
   "metadata": {},
   "source": [
    "### Load data and the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a70eff76-8976-44e5-b80e-1a36f4951cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/markop/work/graphs/.venv/lib/python3.11/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"word_usage_annotations_1997_2018.tsv\", sep='\\t')\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"EMBEDDIA/sloberta\", use_fast=True)\n",
    "model = transformers.AutoModelForMaskedLM.from_pretrained(\"EMBEDDIA/sloberta\", output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b837817-268d-4299-aad6-9b0d4ba93fb0",
   "metadata": {},
   "source": [
    "### Show that we can extract unlematized words from the sentence\n",
    "\n",
    "This step is not part of the approach, but it simplifies preprocessing.\n",
    "The downside of such fuzzy matching is that we have to check if the result is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80dbee52-02c1-4762-844c-b200d3de575b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from thefuzz import process, fuzz\n",
    "import re\n",
    "\n",
    "\n",
    "results1997 = []\n",
    "results2018 = []\n",
    "\n",
    "word_matches = collections.defaultdict(set)\n",
    "\n",
    "for row in df.itertuples():\n",
    "    word, score = process.extractOne(row.word, re.split(r\"\\W+\", row._3), scorer=fuzz.QRatio)\n",
    "    assert score > 50\n",
    "    results1997.append((row._3.find(word), len(word)))\n",
    "    word = word.lower()\n",
    "    if not word.startswith(row.word):\n",
    "        word_matches[row.word].add(word.lower())\n",
    "    word, score = process.extractOne(row.word, re.split(r\"\\W+\", row._4), scorer=fuzz.QRatio)\n",
    "    assert score > 50\n",
    "    word = word.lower()\n",
    "    if not word.startswith(row.word):\n",
    "            word_matches[row.word].add(word.lower())\n",
    "    results2018.append((row._4.find(word), len(word)))\n",
    "\n",
    "\n",
    "df['target_span_1997'] = results1997\n",
    "df['target_span_2018'] = results2018\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab278f4-921f-4ad7-9492-aef61d5aadeb",
   "metadata": {},
   "source": [
    "### Not too many results, can check them manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee7fdaae-7ff5-4ac3-ae69-e747fc909e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "globinski : globinskega, globinske, globinsko, globinska\n",
      "razbitina : razbitin, razbitine, razbitino\n",
      "poizvedba : poizvedbe, poizvedb, poizvedbi, poizvedbo\n",
      "burka : burke, burki, burk, burko\n",
      "zvezdniški : zvezdniško, zvezdniška, zvezdniškemu, zvezdniškega, zvezdniškem, zvezdniške\n",
      "dopisnica : dopisnici, dopisnic, dopisnice, dopisnico\n",
      "kneževina : kneževine, kneževin, kneževini, kneževino\n",
      "dokumentarec : dokumentarcih, dokumentarcev, dokumentarcem, dokumentarce, dokumentarcu, dokumentarci, dokumentarca\n",
      "dobitnica : dobitnico, dobitnic, dobitnici, dobitnice\n",
      "ogaben : ogabnim, ogabni, ogabno, ogabne, ogabnega, ogabna, ogabnih\n",
      "pomočnica : pomočnika, pomočnice, pomočnici, pomočnico, pomočnic\n",
      "misija : misije, misijo, misij, misiji\n",
      "molekula : molekule, molekul\n",
      "nadrealističen : nadrealistična, nadrealističnega, nadrealističnem, nadrealistične, nadrealističnih, nadrealističnimi, nadrealistično, nadrealističnim, nadrealistični, nadrealističnemu\n",
      "jeziček : jezičkov, jezička, jezičku, jezički, jezičkom\n",
      "transparenten : transparentna, transparentnejšega, transparentnimi, transparentno, transparentnem, transparentnih, transparentnejših, transparentnega, transparentne, transparentnim, transparentni\n",
      "kontaktirati : kontaktiralo, kontaktirate, kontaktirajo, kontaktirali, kontaktiramo, kontaktira, kontaktiram, kontaktirala, kontaktiral\n",
      "gazela : gazele, gazeli, gazel, gazelo\n",
      "zapreka : zaprek, zapreko, zapreke\n",
      "kotalka : kotalke, kotalk\n",
      "izobraževalec : izobraževalne, izobraževalce, izobraževalci, izobraževalcem, izobraževalke, izobraževalca, izobraževalcih, izobraževalcev\n",
      "nedonosen : nedonosnem, nedonosna, nedonosnega, nedonosnemu, nedonosno, nedonosne, nedonosni, nedonosnih, nedonosnim\n",
      "vezen : vezno, veznim, vezne, veznem, vezni, vezna, veznega, veznih\n",
      "upravičiti : upravičilo, upravičimo, upravičile, upravičila, upravičijo, upravičil, upraviči, upravičili\n",
      "žvečilen : žvečilna, žvečilnih, žvečilno, žvečilnim, žvečilni, žvečilnimi, žvečite, žvečilnega, žvečilne\n",
      "krajeven : krajevni, krajevno, krajevnem, krajevnimi, krajevnih, krajevna, krajevnega, krajevne\n",
      "mlačen : mlačnim, mlačnega, mlačne, mlačnem, mlačna, mlačno, mlačni, mlačnimi\n",
      "križen : križnim, križna, križnem, križnega, križno, križni, križnimi, križne, križnih, križnemu\n",
      "preslikava : preslikavo, preslikav, preslikave, preslikavi\n",
      "subtilen : subtilnejšega, subtilna, subtilno, subtilnih, najsubtilnejšega, subtilnejšim, subtilne, subtilnejši, subtilnejše, subtilnega, subtilnimi, subtilni\n",
      "deviški : deviška, deviške, deviškem, deviškega, deviško, deviškemu\n",
      "mravlja : mravlje, mravelj\n",
      "replika : repliko, replik, replike, repliki\n",
      "evro : evru, evri, evra\n",
      "plezalka : plezalko, plezalke, plezalki, splezala, plezalk\n",
      "likvidacijski : likvidacijsko, likvidacijskega, likvidacijskem, likvidacijska, likvidacijske\n",
      "vrvica : vrvice, vrvici, vrvico\n",
      "kletka : kletki, kletko, kletk, kletke\n",
      "odreagirati : odreagirala, odreagirajo, odreagiral, odreagirate, odreagiramo, odreagiram, odreagirali, odreagirale, odreagirata, odreagira\n",
      "ikona : ikono, ikoni, ikon, ikone\n",
      "pedalo : pedal, pedali, pedala\n",
      "testen : test, testni, testnih, testno, testne, testnega, testna, testnem, testnim\n",
      "vijolica : vijolice, vijolic, vijolico\n",
      "kvader : kvadroma, kvadrov, kvadra, kvadru, kvadri, kvadrom, kvadre\n",
      "plošček : ploščki, ploščka, ploščkom, ploščke, ploščku\n",
      "zamakniti : zamaknili, zamaknil, zamaknite, zamakne, zamaknejo, zamaknile, zamaknemo, zamaknete, zamaknilo, zamaknila\n",
      "metafora : metafore, metafor, metafori, metaforo\n",
      "divizija : divizije, diviziji, divizijo, divizij\n",
      "poročanje : poročanjih, poročanja, poročanju\n",
      "zgodnji : zgodnjo, zgodnjega, zgodnje, zgodnja, zgodnjem\n",
      "agencijski : agencijskega, agencijsko, agencijskem, agencijske, agencij, agencijska\n",
      "kraten : kratnim, kratna, kratne, kratni, kratnega, kratnemu, kratnih, kratno\n",
      "bizaren : bizarnim, bizarnem, bizarnejšega, bizarnih, bizarnega, bizarne, bizarno, bizarni, bizarna, bizarnimi\n",
      "kotacija : kotacije, kotaciji, kotacijo, kotacij\n",
      "kobila : kobil, kobili, kobilo, dobila, kobile\n",
      "dohodninski : dohodninsko, dohodninskem, dohodninskega, dohodninske, dohodninska\n",
      "izbranec : izbrance, izbrancev, izbrancem, izbranca, izbrancu, izbranci, izbrancih\n",
      "poceniti : poceni, pocenila, pocenilo, pocenili, pocenile, pocenil\n",
      "izkrcanje : izkrcanj, izkrcanji, izkrcanju, izkrcanja\n",
      "zaročiti : zaročili, zaroči, zaročila, zaročil, zaročim\n",
      "elementaren : elementarni, elementarno, elementarnim, elementarne, elementarnejše, elementarnega, elementarnejši, elementarnih, elementarnimi, elementarna, elementarnem\n",
      "plačanec : plačance, plačanca, plačancih, plačanci, plačancev, plačancu\n",
      "tožba : tožbe, tožb, tožbi, tožbo\n",
      "zakrožiti : zakrožijo, zakrožimo, zakrožila, zakrožili, zakrožile, zakrožilo, zakrožil, zakroži\n",
      "galski : galske, galska, galskega, galsko, galskem\n",
      "limonada : limonado, limonadi, limonade, limonad\n",
      "škatla : škatle, škatel, škatlo, škatli\n",
      "buteljka : buteljk, buteljko, buteljki, buteljke\n",
      "izobraževanje : izobraževanj, izobraževanju, izobraževanja\n",
      "umetnica : umetnice, umetnic, umetnika, umetnici, umetnico\n",
      "motociklizem : motociklizma, motociklizmu\n",
      "trofejen : trofejnih, trofejnemu, trofejne, trofejno, trofejnu, trofejna, trofejnega, trofejnim, trofejni, trofejnimi\n",
      "teliček : telička, teličke, teličkih, teličku, teličkom, teličkov, telički\n",
      "nivojski : nivojskega, nivojskem, nivoji, nivojska, nivojsko, nivojskemu, nivojske\n",
      "priključek : priključki, priključkoma, priključkov, priključku, priključka, priključke, priključkom\n",
      "znakoven : znakovni, znakovne, znakovnim, znakovnih, znakovnem, znakov, znakovnega, znakovno, znakovnimi, znakovna\n"
     ]
    }
   ],
   "source": [
    "for w in word_matches:\n",
    "    print(w,\":\", \", \".join(word_matches[w]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c204bc7-a660-4ed7-88a7-31fd4b5dcc78",
   "metadata": {},
   "source": [
    "### Calculate token embeddings\n",
    "\n",
    "We extract unlematized words (as above) and resolve tokens for this word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d264263f-273a-400e-a839-b94f20a0b457",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3150/3150 [04:25<00:00, 11.89it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import torch\n",
    "\n",
    "LAYER = 11\n",
    "results = []\n",
    "\n",
    "def _get_word_tokens(model, tokenizer, sentence, word):\n",
    "    word, score = process.extractOne(word, re.split(r\"\\W+\", sentence), scorer=fuzz.QRatio)\n",
    "    word_start_ix = sentence.find(word)\n",
    "    assert score > 50\n",
    "    # tokenize one by one so we avoid padding > 1/2 zeros (bisect won't work)\n",
    "    tokenized = tokenizer(sentence, return_offsets_mapping=True, return_tensors='pt')\n",
    "    offsets = tokenized['offset_mapping'][0]\n",
    "    end_off = offsets[:, 1].contiguous()\n",
    "    # -1 is the diff between seq[e-1:e] and seq[e]\n",
    "    start_tok = torch.searchsorted(end_off - 1, word_start_ix)\n",
    "    end_tok = torch.searchsorted(end_off, word_start_ix + len(word)) + 1\n",
    "    #print(tokenizer.tokenize(sentence)[start_tok - 1: end_tok - 1])\n",
    "    with torch.no_grad():\n",
    "        tokenized.pop('offset_mapping')\n",
    "        hs = model(**tokenized).hidden_states[-2]  # second to last\n",
    "        tokens = hs[0, start_tok:end_tok]\n",
    "    return tokens\n",
    "    \n",
    "    \n",
    "    \n",
    "for row in tqdm.tqdm(df.itertuples(), total=len(df)):\n",
    "    tokens1 = _get_word_tokens(model, tokenizer, row._3, row.word)\n",
    "    tokens2 = _get_word_tokens(model, tokenizer, row._4, row.word)\n",
    "    results.append((tokens1, tokens2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cd46ac-ce4e-4a7d-928c-ddf043d9c695",
   "metadata": {},
   "source": [
    "### Calculate word embeddings (avg. of the token embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7ece6ff-4377-4f25-a06c-87cd0c3c249f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3150/3150 [00:00<00:00, 25555.58it/s]\n"
     ]
    }
   ],
   "source": [
    "per_word_results1 = collections.defaultdict(list)\n",
    "per_word_results2 = collections.defaultdict(list)\n",
    "\n",
    "\n",
    "for row, (vecs1, vecs2) in tqdm.tqdm(zip(df.itertuples(), results), total=len(df)):\n",
    "    m1 = vecs1.mean(axis=0)\n",
    "    m2 = vecs2.mean(axis=0)\n",
    "    per_word_results1[row.word].append(m1.numpy())\n",
    "    per_word_results2[row.word].append(m2.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b10a6d-2987-4fb0-b238-bd1c0dabf8b3",
   "metadata": {},
   "source": [
    "### The main part of the approach - solve optimal transport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9d518de-5751-4ed5-be93-81852e4da0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ot, scipy\n",
    "import numpy as np\n",
    "\n",
    "word_results = {}\n",
    "\n",
    "for word in per_word_results1:\n",
    "    vecs1 = per_word_results1[word]\n",
    "    vecs2 = per_word_results2[word]\n",
    "    cdist = scipy.spatial.distance.cdist(vecs1, vecs2, 'cosine')\n",
    "    res = ot.lp.emd2([], [], cdist)\n",
    "    word_results[word] = res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310563de-10c6-4fd4-aca4-c58d38b3db36",
   "metadata": {},
   "source": [
    "### Evaluate the approach using Spearman rank correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49da3472-719a-4957-b15a-f8aca46537d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SignificanceResult(statistic=0.6356990720702655, pvalue=4.175558016074771e-13)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = pd.read_csv(\"semantic_shift_scores.tsv\", sep='\\t')\n",
    "calculated_scores = [word_results[r.word] for r in scores_df.itertuples()]\n",
    "calculated_scores\n",
    "scipy.stats.spearmanr(calculated_scores, 4-scores_df.score.values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
